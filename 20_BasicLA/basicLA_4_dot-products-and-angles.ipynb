{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "english-headset",
   "metadata": {},
   "source": [
    "# Dot products, angles, and orthogonality\n",
    "\n",
    "In this section, we review some of the basics of geometry in $\\mathbb{R}^n$.\n",
    "\n",
    "## Dot products and angles\n",
    "\n",
    "### Review of dot products in $\\mathbb{R}^n$\n",
    "\n",
    "One of the most important quantities we compute in linear algebra are _inner products_, also called the _dot product_. \n",
    "For two vectors $x,y \\in \\mathbb{R}^n$, the inner product is the number\n",
    "\n",
    "\n",
    "$$\n",
    "x^\\top y = \\sum_{i=1}^n x_iy_i .\n",
    "$$\n",
    "\n",
    "\n",
    "Importantly, an inner product can be thought of as a linear function from $\\mathbb{R}^n$ to $\\mathbb{R}$: if we fix $y\\in \\mathbb{R}^n$, then the function $T_y(x) = x^\\top y$ is clearly linear, since for any $x,x' \\in \\mathbb{R}^n$ and $\\alpha \\in \\mathbb{R}$, we have\n",
    "\n",
    "\n",
    "$$\n",
    "T_y(x + \\alpha x') = (x+\\alpha x')^\\top y = \\sum_{i=1}^n (x_i + \\alpha x'_i)y_i = \\sum_{i=1}^n x_iy_i + \\alpha\\sum_{i=1}^nx'_iy_i = x^\\top y + \\alpha (x')^\\top y = T_y(x) + \\alpha T_y(x') .\n",
    "$$\n",
    "\n",
    "\n",
    "Dot products are also the basis of matrix multiplication: if $A \\in \\mathbb{R}^{n\\times m}$ and $B\\in \\mathbb{R}^{m\\times p}$ are matrices, and $a_1,\\dots, a_n$ are the rows of $A$ and $b_1,\\dots, b_p$ are the columns of $B$, then the $(i,j)$th element of $AB$ is just $a_i^\\top b_j$. \n",
    "\n",
    "In this chapter, however, we will be interested in a more geometric interpretation of dot products, namely that they are used to compute the angle between two vectors.\n",
    "\n",
    "### Computing angles between vectors with dot products\n",
    "\n",
    "One of the most important facts about dot products is that they give us a way to compute the _angle_ $\\theta$ between any two vectors $x,y\\in \\mathbb{R}^n$. \n",
    "This is due to the following important identity:\n",
    "\n",
    "\n",
    "$$\n",
    "x^\\top y = \\|x\\|_2\\|y\\|_2\\cos(\\theta)\n",
    "$$\n",
    "\n",
    "\n",
    "Therefore we have that the angle $\\theta$ can be found with \n",
    "\n",
    "\n",
    "$$\n",
    "\\theta = \\arccos \\left(\\frac{x^\\top y}{\\|x\\|_2 \\|y\\|_2}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Let's see a few examples in Python. \n",
    "First, let's write a useful function which finds the angle between any two vectors $x$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def angle_between_vectors(x,y):\n",
    "    xty = np.dot(x, y)\n",
    "    norm_x = np.linalg.norm(x)\n",
    "    norm_y = np.linalg.norm(y)\n",
    "    theta = np.arccos(xty/(norm_x*norm_y))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-testament",
   "metadata": {},
   "source": [
    "In this function we first compute the dot product $x^\\top y$, then the norms of $x$ and $y$. \n",
    "Finally, we use `np.arccos` to take the arccosine of $x^\\top y$ divided by $\\|x\\|_2\\|y\\|_2$ to find the angle. \n",
    "\n",
    "Let's look at a simple example to make sure this works. \n",
    "For example, consider $y = (1,1)$ and $x= (1,0)$. \n",
    "The vector $y$ is on the $45^\\circ$ line, and $x$ is on the $x$-axis, and so the angle between them should be $45^\\circ$, or $\\pi/4$. \n",
    "Let's first define and plot these vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.array([1,0])\n",
    "y = np.array([1,1])\n",
    "\n",
    "origin = np.zeros(2)\n",
    "plt.quiver(*origin, *x, label='x', scale=1, units='xy', color='blue')\n",
    "plt.quiver(*origin, *y, label='y', scale=1, units='xy', color='red')\n",
    "plt.grid()\n",
    "\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.ylim(-1.5,1.5)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-newport",
   "metadata": {},
   "source": [
    "As expected, the two vectors appear to be at a $45^\\circ$ angle. \n",
    "Let's use our function to check that this is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = angle_between_vectors(x,y)\n",
    "print('angle between x and y: ', theta)\n",
    "print('pi/4: ', np.pi/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-washington",
   "metadata": {},
   "source": [
    "As expected, the answer is $\\pi/4$. \n",
    "Let's see what happens when we rotate the vectors by some angle. \n",
    "Recall that the matrix which rotates vectors by $\\theta$ degrees is given by\n",
    "\n",
    "\n",
    "$$\n",
    "R_\\theta = \\begin{pmatrix}\\cos(\\theta) & -\\sin(\\theta)\\\\ \\sin(\\theta) & \\cos(\\theta)\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Let's write a quick Python function to create this matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation(theta):\n",
    "    Rtheta = np.array([[np.cos(theta), -np.sin(theta)],[np.sin(theta), np.cos(theta)]])\n",
    "    return Rtheta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-samoa",
   "metadata": {},
   "source": [
    "Now let's try rotating $y$ by $90^\\circ$ (or $\\pi/2$ radians) and $x$ by $45^\\circ$ (or $\\pi/4$) radians, and plot the newly rotated vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "R90 = rotation(np.pi/2)\n",
    "R45 = rotation(np.pi/4)\n",
    "\n",
    "y_rotated = np.dot(R90, y)\n",
    "x_rotated = np.dot(R45, x)\n",
    "\n",
    "plt.quiver(*origin, *x_rotated, label='x rotated by pi/4', scale=1, units='xy', color='blue')\n",
    "plt.quiver(*origin, *y_rotated, label='y rotated by pi/2', scale=1, units='xy', color='red')\n",
    "plt.grid()\n",
    "\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.ylim(-1.5,1.5)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-broadcast",
   "metadata": {},
   "source": [
    "The vectors appear to now by at a $90^\\circ$ angle (which is what we would expect), but we can also verify this using our `angle_between_vectors` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('angle between x (rotated by pi/4) and y (rotated by pi/2): ', angle_between_vectors(x_rotated, y_rotated))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-quebec",
   "metadata": {},
   "source": [
    "The answer is $\\approx 1.5708$, which is just $\\pi/2$. \n",
    "\n",
    "Vectors which are at a $90^\\circ$ angle are special -- they are called _orthogonal_ (or _perpendicular_). \n",
    "\n",
    "### A gotcha\n",
    "\n",
    "One point which is important to keep in mind when computing angles numerically is that we need to be careful when applying the $\\arccos$ function in practice. To meaningfully interpret the angle $\\arccos \\left(\\frac{x^\\top y}{\\|x\\|_2 \\|y\\|_2}\\right)$, we need to have that $-1\\leq \\frac{x^\\top y}{\\|x\\|_2 \\|y\\|_2} \\leq 1$. This is always true mathematically; however, numerically we could run into situations where $x$ and $y$ are parallel, but when we compute $\\frac{x^\\top y}{\\|x\\|_2 \\|y\\|_2}$ we obtain a number like $1.0000000000000002$. In this case, when we take the arccosine, we won't get a meaningful answer (since it is only defined for values in $[-1,1]$. Let's see a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123) #set seed for reproducibility\n",
    "\n",
    "a = np.random.randn(10)\n",
    "b = 1.2340124*a\n",
    "\n",
    "angle_between_vectors(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-contribution",
   "metadata": {},
   "source": [
    " Here our function returns `nan`. We can check that the issue is numerical by computing $\\frac{x^\\top y}{\\|x\\|_2 \\|y\\|_2}$ directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-resource",
   "metadata": {},
   "source": [
    "Indeed, we get a number which is very slightly larger than $1$. In cases like this, it might be reasonable to try and round the value $\\frac{x^\\top y}{\\|x\\|_2 \\|y\\|_2}$.  \n",
    "\n",
    "\n",
    "## Orthogonal vectors, bases, and matrices\n",
    "\n",
    "Let's see what it means for two vectors to be orthogonal in terms of their dot product. \n",
    "If the angle between $x$ and $y$ is $90^\\circ$ (or $\\pi/2$ radians), then\n",
    "\n",
    "\n",
    "$$\n",
    "\\arccos \\left(\\frac{x^\\top y}{\\|x\\|_2 \\|y\\|_2}\\right) = \\pi/2 \\iff \\frac{x^\\top y}{\\|x\\|_2 \\|y\\|_2} = \\cos(\\pi/2) = 0 \\iff x^\\top y= 0\n",
    "$$\n",
    "\n",
    "\n",
    "Therefore, two vectors $x$ and $y$ are _orthogonal_ if and only if their dot product is zero. \n",
    "Orthogonal vectors play an important role in linear algebra. \n",
    "In particular, we can define orthogonality between two vectors, between a vector and a subspace, and between two subspaces.\n",
    "\n",
    "### Orthogonality between two subspaces\n",
    "\n",
    "The notion of orthogonality is also easily extended to the span of two sets of vectors. For example, consider matrices $A \\in \\mathbb{R}^{n\\times k}$ and $B \\in \\mathbb{R}^{n\\times p}$, and let $a_1,\\dots,a_k \\in \\mathbb{R}^n$ and $b_1,\\dots, b_p\\in \\mathbb{R}^n$ be their columns. Given these matrices, we can define the following special subspaces of $\\mathbb{R}^n$: $V_A = \\text{span}(a_1,\\dots,a_k)$ and $V_B = \\text{span}(b_1,\\dots,b_p)$. $V_A$ and $V_B$ are called the _column spaces_ of $A$ and $B$, respectively. Then we say that the subspaces $V_A$ and $V_B$ are _orthogonal_ if and only if $a_i^\\top b_j = 0$ for all $i=1,\\dots,k$ and $j=1,\\dots,p$. Since we know that the the $(i,j)$th element of $A^\\top B$ is exactly $a_i^\\top b_j$, this is equivalent to saying that $A^\\top B = \\mathbf{0}$ where $\\mathbf{0}$ is the $k\\times p$ matrix of all zeros.\n",
    "\n",
    "As a special case of this, we have that a vector $x = \\begin{pmatrix}x_1\\\\ \\vdots \\\\ x_n\\end{pmatrix}$ is orthogonal to the column space of $A$ if $Ax=0$. In this case, we say that $x$ is in the _null space_ of $A$.  We also may use the notation $\\text{null}(A)$ to denote the set of vectors $x$ such that $Ax= 0$. This set is also a subspace of $\\mathbb{R}^n$. \n",
    "\n",
    "To understand this visually, let's consider the matrix $A$ given below\n",
    "\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix}1 & 0\\\\ 2& 3\\\\ 3&2\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Let's define the columns as vectors $a_1 = \\begin{pmatrix}1\\\\2\\\\3\\end{pmatrix}$ and $a_2 = \\begin{pmatrix}0\\\\3\\\\2\\end{pmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([1,2,3])\n",
    "a2 = np.array([0,3,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-somewhere",
   "metadata": {},
   "source": [
    "The subspace $V_A = \\text{span}(a_1,a_2)$ is a plane in $\\mathbb{R}^3$, which we can visualize with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = np.cross(a1, a2)\n",
    "a, b, c = cp\n",
    "\n",
    "origin = np.zeros(3) \n",
    "\n",
    "d = np.dot(cp, origin)\n",
    "\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "ax.quiver(*origin,*a1, length=1, arrow_length_ratio=0.1, colors='b', label='a1') \n",
    "ax.quiver(*origin,*a2, length=1, arrow_length_ratio=0.1, colors='g', label='a2') \n",
    "\n",
    "ax.legend()\n",
    "xx, yy = np.meshgrid(np.arange(-5,8), np.arange(-5,8))\n",
    "q = (d - a * xx - b * yy) / c\n",
    "\n",
    "ax.plot_surface(xx, yy, q, alpha=0.5)\n",
    "ax.view_init(15, 120)\n",
    "\n",
    "plt.grid()\n",
    "ax.set_xlim(-5,6)\n",
    "ax.set_ylim(-5,6)\n",
    "ax.set_zlim(-5,6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-launch",
   "metadata": {},
   "source": [
    "Now let's find a vector that's orthogonal to the _subspace_ $V_A$. Such a vector $x = \\begin{pmatrix}x_1 \\\\ x_2 \\\\ x_3\\end{pmatrix}$ satisfies\n",
    "\n",
    "\n",
    "$$\n",
    "0 = a_1^\\top x = x_1 + 2x_2 + 3x_3\\;\\;\\; \\text{ and }\\;\\;\\; 0 = a_2^\\top x = 3x_2 + 2x_3\n",
    "$$\n",
    "\n",
    "\n",
    "With some algebra, it is easy to verify that any vector $x$ of the form $x = \\begin{pmatrix}\\frac{5}{2}\\alpha \\\\ \\alpha \\\\ -\\frac{3}{2}\\alpha\\end{pmatrix}$ will satisfy these conditions. Let's see an example with $\\alpha = -2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = -2\n",
    "\n",
    "x = np.array([5/2*alpha, alpha, -3/2*alpha])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-approach",
   "metadata": {},
   "source": [
    "Now let's plot $x$ and see that it is in fact orthogonal to the plane $V_A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = np.cross(a1, a2)\n",
    "a, b, c = cp\n",
    "\n",
    "origin = np.zeros(3)\n",
    "\n",
    "d = np.dot(cp, origin)\n",
    "\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "ax.quiver(*origin,*a1, length=1, arrow_length_ratio=0.1, colors='b', label='a1') \n",
    "ax.quiver(*origin,*a2, length=1, arrow_length_ratio=0.1, colors='g', label='a2') \n",
    "ax.quiver(*origin,*x, length=1, arrow_length_ratio=0.1, colors='r', label='x') \n",
    "\n",
    "ax.legend()\n",
    "xx, yy = np.meshgrid(np.arange(-5,8), np.arange(-5,8))\n",
    "q = (d - a * xx - b * yy) / c\n",
    "\n",
    "ax.plot_surface(xx, yy, q, alpha=0.5)\n",
    "ax.view_init(15, 120)\n",
    "\n",
    "plt.grid()\n",
    "ax.set_xlim(-5,6)\n",
    "ax.set_ylim(-5,6)\n",
    "ax.set_zlim(-5,6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-indiana",
   "metadata": {},
   "source": [
    "As we can see, not only is the vector $x$ orthogonal to both the vectors $a_1$ and $a_2$, but it is in fact orthogonal to the entire subspace $V_A$. \n",
    "\n",
    "\n",
    "### Orthogonal and orthonormal sets and bases\n",
    "\n",
    "Before defining what an orthogonal basis is, we first cover what it means for a set of vectors to be orthogonal. \n",
    "A set $V = \\{v_1,\\dots,v_k\\}$ of vectors $v_1,\\dots,v_k \\in \\mathbb{R}^n$ is called an _orthogonal set_ if $v_i^\\top v_j = 0$ for any $i\\neq j$. \n",
    "Since a basis is just a linearly indepedent set of vectors which spans a vector space, an _orthogonal basis_ is simply a basis which is also orthogonal. \n",
    "\n",
    "For example, the standard basis in $\\mathbb{R}^n$ is orthogonal. \n",
    "Here the standard basis is the set $E = \\{e_1,\\dots, e_n\\}$ where \n",
    "\n",
    "\n",
    "$$\n",
    "e_i = \\begin{pmatrix}0\\\\ \\vdots \\\\1\\\\ \\vdots \\\\ 0\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "i.e., it is $1$ in the $i^{th}$ coordinate and $0$ elsewhere. \n",
    "Then since for $i\\neq j$, the vectors $e_i$ and $e_j$ don't have any non-zero entries in common, it is easy to see that $e_i^\\top e_j = 0$. \n",
    "Hence the set $E$ is an orthogonal set, and since we know it is a basis, it is also an orthogonal basis!\n",
    "\n",
    "It turns out that requiring a set to be orthogonal an linearly independent is superfluous: every orthogonal set is automatically linearly independent (though the converse is not true). \n",
    "We won't prove this here, but it is a good exercise to try on your own. \n",
    "Therefore, an orthogonal basis for $\\mathbb{R}^n$ is any orthogonal set of vectors which spans $\\mathbb{R}^n$. \n",
    "While the standard basis is an easy example, it is not the only example. \n",
    "For instance, any rotation of the standard basis is also an orthogonal basis. \n",
    "\n",
    "For example, let's start with the standard basis in $\\mathbb{R}^2$:\n",
    "\n",
    "\n",
    "$$\n",
    "e_1 = \\begin{pmatrix}1\\\\ 0\\end{pmatrix},\\;\\;\\; e_2 = \\begin{pmatrix}0\\\\ 1\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Let's define these in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = np.array([1,0])\n",
    "e2 = np.array([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-touch",
   "metadata": {},
   "source": [
    "Now, let's try rotating these vectors by $45^\\circ$. \n",
    "To do this, we can use the rotation matrix that we defined in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "R45 = rotation(np.pi/4)\n",
    "\n",
    "v1 = np.dot(R45, e1)\n",
    "v2 = np.dot(R45, e2)\n",
    "\n",
    "print('v1 = ', v1)\n",
    "print('v2 = ', v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-spouse",
   "metadata": {},
   "source": [
    "This gives the vectors\n",
    "\n",
    "\n",
    "$$\n",
    "v_1 = \\begin{pmatrix}1/\\sqrt{2}\\\\ 1/\\sqrt{2}\\end{pmatrix},\\;\\;\\; v_2 = \\begin{pmatrix}-1/\\sqrt{2}\\\\ 1/\\sqrt{2}\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Let's check that these vectors are still orthogonal, but in two different ways. \n",
    "First, we can use the `angle_between_vectors` function to check that the angle between $v_1$ and $v_2$ is indeed $90^\\circ$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_between_vectors(v1,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-blank",
   "metadata": {},
   "source": [
    "As expected, we get $\\pi/2$ back. \n",
    "On the other hand, we can also check that $v_1^\\top v_2 = 0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(v1,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-aspect",
   "metadata": {},
   "source": [
    "The set $\\{v_1,v_2\\}$ is not only an orthogonal set, but it is in fact an _orthonormal set_. \n",
    "This means that the vectors are orthogonal, but are also unit vectors. \n",
    "Given an orthogonal set, it is easy to construct an othonormal set by simply dividing each vector in the set by its norm. \n",
    "If $V = \\{v_1,\\dots, v_k\\}$ is an orthonormal set, then we have\n",
    "\n",
    "\n",
    "$$\n",
    "v_i^\\top v_j = \\begin{cases}1 & \\text{if } i=j\\\\ 0 & \\text{if } i\\neq j\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "### Orthogonal matrices\n",
    "\n",
    "Suppose we have an orthonormal set of vectors $V = \\{v_1,\\dots,v_k\\}$, where $v_i \\in \\mathbb{R}^n$. \n",
    "We can stack these vectors into a $n\\times k$ matrix $Q$, with $v_i$ being the $i$th column of $Q$:\n",
    "\n",
    "\n",
    "$$\n",
    "Q = \\begin{pmatrix}|&|&&|\\\\ v_1 & v_2 & \\cdots & v_k\\\\ |&|&&|\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Let's see what happens what we compute the matrix $Q^\\top Q$. \n",
    "Since $Q$ is $n\\times k$, $Q^\\top Q$ is a $k\\times k$. \n",
    "As we mentioned earlier in this section, the $(i,j)$th entry of $Q^\\top Q$ is just $v_i^\\top v_j$. \n",
    "Therefore, we have the following description of the entries of $Q^\\top Q$:\n",
    "\n",
    "\n",
    "$$\n",
    "[Q^\\top Q]_{ij} = v_i^\\top v_j = \\begin{cases}1 & \\text{if } i=j\\\\ 0 & \\text{if } i\\neq j\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "Therefore, the diagonal entries of $Q$ are $1$ and the off-diagonal entries are 0. \n",
    "Said another way, $Q^\\top Q = I$ -- i.e., it is the identity matrix on $\\mathbb{R}^k$. \n",
    "Any matrix $Q$ which satisfies $Q^\\top Q = I$ is called an _orthogonal matrix_. \n",
    "Equivalently, an orthogonal matrix is a matrix whose columns form an orthonormal set.\n",
    "\n",
    "**Remark:** One point that often causes confusion is that an orthogonal matrix $Q$ doesn't just have _orthogonal_ columns, but rather _orthonormal_ columns. \n",
    "Perhaps it would make more sense to call such a matrix $Q$ an orthonormal matrix, but unfortunately this terminology is now standard, and so it is important to remember this distinction.\n",
    "\n",
    "Let's see a few examples of orthogonal matrices in Python. \n",
    "We can start with our set $\\{v_1,v_2\\}$ that we defined above, from rotating the standard basis by $45^\\circ$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.stack([v1,v2], axis=1)\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-hampton",
   "metadata": {},
   "source": [
    "Let's check that $Q^\\top Q = I$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(Q.T, Q).round(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-moldova",
   "metadata": {},
   "source": [
    "Here we round to 8 decimals to avoid issues of numerical precision (though in practice you may want to be careful when doing this). \n",
    "In fact, since the matrix $Q$ is square in this case, we observe that $Q^{-1} = Q^\\top$. \n",
    "This relationship is true for any square orthogonal matrix.\n",
    "\n",
    "We can also look at a bigger example. \n",
    "For now, we won't explain how the below method works; we will cover this in the next section of the workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "k = 5\n",
    "\n",
    "A = np.random.randn(n, k)\n",
    "Q, _ = np.linalg.qr(A)\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-lawrence",
   "metadata": {},
   "source": [
    "Let's check that the $10\\times 5$ matrix $Q$ is in fact orthogonal, by checking that $Q^\\top Q = I$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(Q.T, Q).round(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-power",
   "metadata": {},
   "source": [
    "Indeed it is.\n",
    "\n",
    "In the above code, we used something called a $QR$ decomposition to generate the othogonal matrix $Q$. \n",
    "This is a generic method which we can use to find an orthogonal set from any given set of vectors in $\\mathbb{R}^n$. \n",
    "This is one of the most important decompositions in linear algebra, and we will discuss it in much more detail in the next sections of the workbook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
